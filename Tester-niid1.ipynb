{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_avg_sdev import plot_avgsdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "file_list = list(filter(os.path.isfile, glob.glob('./Results_2/' + '*')))\n",
    "file_list.sort(key=lambda x: os.path.getmtime(x), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = []\n",
    "for result_file in file_list[:5]:\n",
    "    result_files.append(result_file.split('/')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fashion_niid2_n30_c5_e2_20211103-0950',\n",
       " 'fashion_niid2_n30_c5_e2_20211103-0810',\n",
       " 'cifar_niid2_n30_c5_e2_20211103-0725',\n",
       " 'mnist_iid_n30_c5_e2_20211103-0549',\n",
       " 'fashion_niid_n30_c5_e2_20211103-0427']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['test_acc', 'trg_loss',  'avg_acc', 'cluster_graph'] # 'cluster_avgacc'\n",
    "for resultfile in result_files:\n",
    "    for metric in metrics:\n",
    "        plot_avgsdev(metric, resultfile, './Results_2/', './Results_2/Figures/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open (file_list[1], 'rb') as f:\n",
    "    state = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_set = [[27, 12, 13, 9], [12, 29, 18, 8, 2], [28, 21, 0, 13], [25, 1, 6], [25, 4, 7, 17], [26, 18, 12, 4], [24, 11, 25], [20, 12, 10]]\n",
    "cluster_graph = nx.Graph()\n",
    "for i in range(len(cluster_set)):\n",
    "    temp = nx.complete_graph(cluster_set[i])\n",
    "    cluster_graph = nx.compose(cluster_graph, temp)\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "13\n",
      "9\n",
      "29\n",
      "18\n",
      "8\n",
      "2\n",
      "26\n",
      "4\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in cluster_graph.neighbors(12):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[27, 12, 13, 9],\n",
       " [12, 29, 18, 8, 2],\n",
       " [28, 21, 0, 13],\n",
       " [25, 1, 6],\n",
       " [25, 4, 7, 17],\n",
       " [26, 18, 12, 4],\n",
       " [24, 11, 25],\n",
       " [20, 12, 10]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "cluster_size = [4, 5, 4, 3, 4, 4, 3, 3]\n",
    "num_nodes = 30\n",
    "node_list = list(range(num_nodes))\n",
    "random.shuffle(node_list)\n",
    "cluster_set = []\n",
    "for size in cluster_size:\n",
    "    if size < len(node_list):\n",
    "        temp = random.sample(node_list, size)\n",
    "    else:\n",
    "        node_list = [item for item in node_list if item not in temp]\n",
    "#     add_factor = np.random.randint(1, 3)\n",
    "#     add = random.sample(list(range(num_nodes)),  add_factor)\n",
    "#     for add_node in add:\n",
    "#         if add_node not in temp:\n",
    "#             temp = temp + add\n",
    "    cluster_set.append(temp)\n",
    "print(cluster_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_avg_sdev import plot_avgsdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from plot_avg_sdev import plot_avgsdev\n",
    "metrics = ['test_acc', 'trg_loss',  'avg_acc', 'cluster_graph']\n",
    "files = os.listdir('./Results_2/')\n",
    "for file in files:\n",
    "    if 'n30' in file:\n",
    "        for metric in metrics:\n",
    "            plot_avgsdev(metric, file, './Results_2/', './Results_2/Figures/')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CONDA_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "cluster_set =[[8, 2, 10, 17, 6, 2, 1, 14], [1, 13, 18, 3, 16], [7, 3, 11, 16, 4, 7, 16, 10], [14, 9, 12, 19, 5, 15, 0, 4, 16, 1, 10]]\n",
    "cluster_graph = nx.Graph()\n",
    "# Generate Graph\n",
    "for i in range(len(cluster_set)):\n",
    "    temp = nx.complete_graph(cluster_set[i])\n",
    "    cluster_graph = nx.compose(cluster_graph, temp)\n",
    "    del temp\n",
    "nx.draw(cluster_graph, with_labels = True) \n",
    "agg_neighborhood = []\n",
    "num_nodes = 20\n",
    "for node in range(num_nodes):\n",
    "    neighborhood = [neighbors for neighbors in cluster_graph.neighbors(node)]\n",
    "    neighborhood.append(node)\n",
    "    agg_neighborhood.append(neighborhood)\n",
    "agg_neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the Fashion-MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Hard coded-Clusters:\n",
    "    # cluster_size = []\n",
    "    # for i range(num_clusters):\n",
    "    #     cluster_size = np.random.randint(min_cluster_size, max_cluster_size, num_clusters-1)\n",
    "    #     print(cluster_size)\n",
    "    #     last_element = num_nodes - cluster_size.sum()\n",
    "    #     cluster_size = np.append(cluster_size, last_element)\n",
    "\n",
    "    cluster_size = [5, 3, 4, 8]\n",
    "    node_list = list(range(num_nodes))\n",
    "    random.shuffle(node_list)\n",
    "    cluster_set = []\n",
    "    for size in cluster_size:\n",
    "        temp = random.sample(node_list, size)\n",
    "        node_list = [item for item in node_list if item not in temp]\n",
    "        add_factor = np.random.randint(2, 5)\n",
    "        add = random.sample(list(range(num_nodes)),  add_factor)\n",
    "        temp = temp + add\n",
    "        cluster_set.append(temp)\n",
    "    print(cluster_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate main graph    \n",
    "cluster_graph = nx.Graph()\n",
    "# Generate Graph\n",
    "for i in range(len(cluster_set)):\n",
    "    temp = nx.complete_graph(cluster_set[i])\n",
    "    cluster_graph = nx.compose(cluster_graph, temp)\n",
    "    del temp\n",
    "    \n",
    "nx.draw(cluster_graph, with_labels = True, font_weight = 'bold')\n",
    "plt.title('Clustered D2D Setting')\n",
    "plt.savefig('Cluster Configuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from DNN import *\n",
    "from data_utils import *\n",
    "from data_dist import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from train_round import *\n",
    "import matplotlib.pyplot as plt\n",
    "from d2denvironment import *\n",
    "from results_plots import final_list\n",
    "import statistics\n",
    "import networkx as nx\n",
    "dataset = 'mnist'\n",
    "num_nodes = 4\n",
    "train, test = dataset_select(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindist = data_iid(train, num_nodes)\n",
    "base_model = Net(10, 1, dataset)\n",
    "sgd_model = copy.deepcopy(base_model).cuda()\n",
    "models = {node:copy.deepcopy(base_model).cuda() for node in range(num_nodes)}\n",
    "optim_set = {node:torch.optim.SGD(model.parameters(), lr = 0.01) for node, model in models.items()}\n",
    "\n",
    "trgloss_dict = {node:[] for node in range(num_nodes)}\n",
    "for rnd in range(10):\n",
    "    loss_dict, _ = local_update(3, models, 10, 1, train, traindist, 8)\n",
    "    aggregated_model = server_aggregate(models, list(range(num_nodes)), 10, 1, dataset)\n",
    "    for node, loss in loss_dict.items():\n",
    "                    trgloss_dict[node] += loss\n",
    "            \n",
    "for node in range(num_nodes):\n",
    "    plt.figure()\n",
    "    plt.plot(trgloss_dict[node])\n",
    "    \n",
    "loss_dict = {node:[] for node in range(num_nodes)}\n",
    "models2 = {node:copy.deepcopy(base_model).cuda() for node in range(num_nodes)}\n",
    "optim_set = {node:torch.optim.SGD(model.parameters(), lr = 0.01) for node, model in models2.items()}\n",
    "for rnd in range(10):\n",
    "    for node, model in models2.items():\n",
    "        for epoch in tqdm(range(3)):\n",
    "            loss = client_update(model, optim_set[node], DataLoader(DataSubset(train, traindist, node), batch_size = 16)) \n",
    "            loss_dict[node].append(loss)\n",
    "    base_model = Net(10, 1, dataset).cuda()\n",
    "    for key in base_model.state_dict().keys():\n",
    "        for node, model in models.items():\n",
    "            base_model.state_dict()[key] += model.state_dict()[key]\n",
    "        base_model.state_dict()[key] = torch.div(base_model.state_dict()[key], len(models))\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "for node in range(num_nodes):\n",
    "    plt.figure()\n",
    "    plt.plot(loss_dict[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result_files = os.listdir('./Results/No_Strag/')\n",
    "# result_files = []\n",
    "# for file in files:\n",
    "#     if 'results' in file:\n",
    "#         result_files.append(file)\n",
    "# result_files.remove(result_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_files = ['0136', '2144', '0207', '1420', '0805', '0417']\n",
    "\n",
    "for file in result_files:\n",
    "    for target in target_files:\n",
    "        if target in file:\n",
    "            filename = os.path.join('./Results/', file)\n",
    "            with open(filename, 'rb') as f:\n",
    "                state_latest =  pickle.load(f)\n",
    "            print(target)\n",
    "            print(state_latest[4]['d2d'][-1])\n",
    "            print('\\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(state_latest[4]['d2d_clus'])\n",
    "plt.xlabel('Aggregation Rounds', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['test_acc', 'trg_loss', 'cluster_avgacc', 'avg_acc', 'cluster_graph']\n",
    "for file in result_files:\n",
    "    for metric in metrics:\n",
    "        avgs = plot_avg_sdev(metric, file, './Results/No_Strag/', './Results/No_Strag/Results/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_sdev(metric, file_name, folder, dest_path, active_ref = False):\n",
    "    file = os.path.join('.', folder, file_name)\n",
    "    with open(file, 'rb') as f:\n",
    "        state =  pickle.load(f)\n",
    "    if len(state) < 6:\n",
    "        return\n",
    "    labels = ['mnist', 'cifar']    \n",
    "    cats = file_name.split('_')\n",
    "    for dataset in labels:\n",
    "        if dataset in cats[0]:\n",
    "            label = dataset\n",
    "            break\n",
    "\n",
    "    dists = ['niid2', 'niid1', 'niid']\n",
    "    for label_dist in dists:\n",
    "        if label_dist in cats[1]:\n",
    "            dist = label_dist\n",
    "            break\n",
    "        else:\n",
    "            dist = 'iid'\n",
    "\n",
    "    modes = ['d2d_clus', 'd2d', 'centr_fed']\n",
    "    ref_mode = 'sgd'\n",
    "    metrics = ['test_acc', 'trg_loss', 'avg_loss', 'divergence', 'avg_acc', 'cluster_set', 'cluster_avgacc']\n",
    "    \n",
    "    metric_order = {metric:order for order, metric in enumerate(metrics)}\n",
    "   \n",
    "    title_div = metric.upper() + '_' +  label.upper() + '_' + dist.upper() +'-' + cats[2].upper() +'_' + cats[3] + '_' + cats[4]\n",
    "    if metric == 'test_acc' or metric == 'trg_loss':\n",
    "        mode_roundstat = {mode:[] for mode in modes}\n",
    "        mode_roundupper = {mode:[] for mode in modes}\n",
    "        mode_roundlower = {mode:[] for mode in modes}\n",
    "        mode_round_avgstat = {mode:[] for mode in modes}\n",
    "        \n",
    "        figure = plt.figure(figsize = (15, 10))\n",
    "        for mode in modes:\n",
    "            # List of nodes part of clusters\n",
    "            nodes_list = final_list(state[5], len(state[metric_order[metric]][mode]))\n",
    "\n",
    "            for rnd in range(len(state[metric_order[metric]][mode][0])):\n",
    "                round_stat = []\n",
    "                round_mean = 0\n",
    "                round_sdev = 0\n",
    "\n",
    "                for node in nodes_list:\n",
    "                    round_stat.append(state[metric_order[metric]][mode][node][rnd])\n",
    "\n",
    "                mode_roundstat[mode].append(round_stat)\n",
    "                round_mean = statistics.mean(round_stat)\n",
    "                round_sdev = statistics.stdev(round_stat)\n",
    "\n",
    "                mode_round_avgstat[mode].append(round_mean)\n",
    "                mode_roundupper[mode].append(round_mean + round_sdev)\n",
    "                mode_roundlower[mode].append(round_mean - round_sdev)\n",
    "\n",
    "            plt.grid()\n",
    "            plt.plot(mode_round_avgstat[mode])\n",
    "            plt.fill_between(list(range(len(mode_roundupper[mode]))), mode_roundupper[mode], mode_roundlower[mode], alpha = 0.3)\n",
    "\n",
    "        if active_ref:\n",
    "            plt.plot(state[metric_order[metric]][ref_mode])\n",
    "            modes.append(ref_mode)\n",
    "            plt.legend(modes)\n",
    "            modes.remove(ref_mode)\n",
    "        else:\n",
    "            plt.legend(modes)\n",
    "        plt.xlabel('Rounds', size = 16)\n",
    "        plt.ylabel(metric.upper(), size = 16)\n",
    "        plt.title(title_div, size = 20)\n",
    "        filename = title_div + '_' + cats[5]\n",
    "        save_path = os.path.join(dest_path, filename)\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(figure)\n",
    "            \n",
    "    elif metric == 'avg_loss' or metric == 'avg_acc':\n",
    "        \"Plotting node averages\"\n",
    "        figure = plt.figure(figsize = (15,10))\n",
    "        plt.grid()\n",
    "        for mode in modes:\n",
    "            plt.plot(state[metric_order[metric]][mode], linewidth = 4)\n",
    "            plt.xlabel('Rounds', fontsize = 16)\n",
    "            plt.ylabel(metric.upper(), fontsize = 16)\n",
    "            plt.title(title_div, size = 20)\n",
    "        if active_ref:\n",
    "            plt.plot(state[metric_order[metric]][ref_mode], linewidth = 4)\n",
    "            modes.append(ref_mode)\n",
    "            plt.legend(modes, fontsize = 16)\n",
    "            modes.remove(ref_mode)\n",
    "        else:\n",
    "            plt.legend(modes, fontsize = 14)\n",
    "\n",
    "        filename = title_div + '_' + cats[5]\n",
    "        save_path = os.path.join(dest_path, filename)\n",
    "        plt.savefig(save_path)        \n",
    "        plt.close(figure)\n",
    "        \n",
    "    elif 'divergence' in metric:\n",
    "        num_rounds = len(state[metric_order[metric]])\n",
    "        modes = list(state[metric_order[metric]][0].keys())\n",
    "        divergence = {mode:None for mode in modes}\n",
    "        figure = plt.figure(figsize = (15,10))\n",
    "\n",
    "        for mode in modes:\n",
    "            nn_divergence = {key:[] for key in state[metric_order[metric]][0][mode].keys()}\n",
    "            for nn_key in state[metric_order[metric]][0][mode].keys():\n",
    "                if 'weight' in nn_key:\n",
    "                    for rnd in range(num_rounds):\n",
    "                        round_divergence = 0\n",
    "                        for i in range(len(state[metric_order[metric]][0][mode][nn_key])):\n",
    "                            round_divergence += state[metric_order[metric]][rnd][mode][nn_key][i].item()\n",
    "                        round_divergence = round_divergence / i\n",
    "                        nn_divergence[nn_key].append(round_divergence)\n",
    "            divergence[mode] = nn_divergence\n",
    "            legends = []\n",
    "            for keys in nn_divergence.keys():\n",
    "                if 'weight' in keys:\n",
    "                    plt.plot(divergence[mode][keys])\n",
    "                    legends.append(keys)\n",
    "            plt.legend(legends)\n",
    "            plt.title(title_div, size = 20)\n",
    "        filename = title_div + '_' + cats[5]\n",
    "        save_path = os.path.join(dest_path, filename)\n",
    "        plt.savefig(save_path)        \n",
    "        plt.close(figure)\n",
    "        \n",
    "    elif 'cluster_avgacc' in metric:\n",
    "        \n",
    "        cluster_set = state[5]\n",
    "        cluster_avgacc = {mode:None for mode in modes}\n",
    "        cluster_avgstat = {cluster_id:[] for cluster_id in range(len(cluster_set))}\n",
    "        \n",
    "        for mode in modes:\n",
    "            for cluster_id in range(len(cluster_set)):\n",
    "                for rnd in range(len(state[0][mode][0])):\n",
    "                    acc = 0\n",
    "                    for node in cluster_set[cluster_id]:\n",
    "                        acc += state[0][mode][node][rnd]\n",
    "                    acc = acc / len(cluster_set[cluster_id])\n",
    "                    cluster_avgstat[cluster_id].append(acc)\n",
    "            cluster_avgacc[mode] = cluster_avgstat\n",
    "        \n",
    "        return cluster_avgacc\n",
    "    \n",
    "    elif metric == 'cluster_graph':\n",
    "        cluster_set = state[5]\n",
    "        figure = plt.figure(figsize = (7.5,5))\n",
    "        cluster_graph = nx.Graph()\n",
    "        for i in range(len(cluster_set)):\n",
    "            temp = nx.complete_graph(cluster_set[i])\n",
    "            cluster_graph = nx.compose(cluster_graph, temp)\n",
    "            del temp\n",
    "        nx.draw(cluster_graph, with_labels = True, font_weight = 'bold')\n",
    "        plt.title(title_div, size = 15)\n",
    "        filename = title_div + '_' + cats[5]\n",
    "        save_path = os.path.join(dest_path, filename)\n",
    "        plt.savefig(save_path)        \n",
    "        plt.close(figure)\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def plot_bar(file_name):\n",
    "    file = './Results/Results-2/' + file_name\n",
    "    with open(file, 'rb') as f:\n",
    "        state =  pickle.load(f)\n",
    "    num_nodes = len(state[0]['d2d_clus'])\n",
    "    labels = ['mnist', 'cifar']\n",
    "    \n",
    "    cats = file_name.split('_')\n",
    "        \n",
    "    for dataset in labels:\n",
    "        if dataset in cats[0]:\n",
    "            label = dataset\n",
    "            break\n",
    "            \n",
    "    dists = ['niid2', 'niid1', 'niid']\n",
    "    for label_dist in dists:\n",
    "        if label_dist in cats[1]:\n",
    "            dist = label_dist\n",
    "            break\n",
    "        else:\n",
    "            dist = 'iid'\n",
    "            \n",
    "    gap = 0.35\n",
    "    keys = np.array(list(range(num_nodes)))\n",
    "    fig1 = plt.figure(figsize = (20, 10))\n",
    "    plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "    plt.grid()\n",
    "    plt.bar(keys-gap/2, state[0]['d2d_clus'].values(), gap-0.2, label = 'd2d_clus')\n",
    "    plt.bar(keys, state[0]['d2d'].values(), gap-0.2)\n",
    "    plt.bar(keys+gap/2, state[0]['centr_fed'].values(), gap-0.2)\n",
    "    plt.legend(['Clustered D2D', 'D2D', 'Centr FL'])\n",
    "    title_acc = 'Accuracy Comparison for ' + label.upper() + ' : ' + dist.upper()\n",
    "    plt.title(title_acc, size = 30)\n",
    "    plt.xlabel('Nodes', size = 20)\n",
    "    plt.ylabel('Accuracies', size = 20)\n",
    "    plt.savefig('./Fig_results/' + title_acc + cats[2])\n",
    "    \n",
    "    for mode in state[0].keys():\n",
    "        if mode != 'sgd':\n",
    "            fig = plt.figure(figsize = (15,10))\n",
    "            plt.grid()\n",
    "            title_loss = 'Loss Comparison for ' + mode.upper() + ' ' + label.upper() + ' : ' + dist.upper()\n",
    "            for node in state[1][mode].keys():\n",
    "                plt.plot(state[1][mode][node])\n",
    "                plt.xlabel('Aggregation Rounds', size = 20)\n",
    "                plt.ylabel('Training Loss', size = 20)\n",
    "                plt.title(title_loss, size = 30)\n",
    "            plt.savefig('./Fig_results/' + title_loss + cats[2])\n",
    "    \n",
    "    fig = plt.figure(figsize  = (15, 10))\n",
    "    plt.grid()\n",
    "    \n",
    "    for mode in state[0].keys():\n",
    "        title_avgloss = 'Average Loss Comparison for ' + label.upper() + ' : ' + dist.upper()\n",
    "        if mode != 'sgd':\n",
    "            plt.plot(state[2][mode])\n",
    "        plt.legend([mode for mode in state[0].keys() if mode != 'sgd'])\n",
    "        plt.title(title_avgloss, size = 25)\n",
    "        plt.xlabel('Aggregation Rounds', size = 20)\n",
    "        plt.ylabel('Average Training Loss for Nodes', size = 20)\n",
    "        plt.savefig('./Fig_results/' + title_avgloss + cats[2])\n",
    "        \n",
    "    nonsgd_modes = ['d2d_clus', 'd2d', 'centr_fed']\n",
    "    divergence = {mode:[] for mode in nonsgd_modes}\n",
    "    for mode in nonsgd_modes:\n",
    "        for i in range(len(state[3][0][mode])):\n",
    "            divergence[mode].append(state[3][0][mode][i].item())  \n",
    "    keys = np.array(list(range(len(divergence[mode]))))\n",
    "    i = -0.3\n",
    "    plt.figure(figsize = (25, 10))\n",
    "    plt.bar( keys+i, divergence['d2d_clus'], 0.2)\n",
    "    plt.bar( keys, divergence['d2d'], 0.2)\n",
    "    plt.legend(['D2D_Clus', 'D2D'])\n",
    "    plt.xlabel('Rounds', size = 20)\n",
    "    title_div = 'Divergence Comparison for ' + label.upper() + ' : ' + dist.upper()\n",
    "    plt.ylabel(title_div, size =20)\n",
    "    plt.title(title_div, size =30)\n",
    "    plt.savefig('./Fig_results/' + title_div + cats[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
